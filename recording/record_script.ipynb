{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c205ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNNING_LOCALLY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6642660a-1238-488f-be01-63a2f2e3325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# PLEASE SET YOUR OWN WORKING_DIRECTORY WHEN RUNNING LOCALLY\n",
    "WORKING_DIRECTORY = \"/home/yash/Desktop/Courses/CS2470/Final_Project/working_dir/\"\n",
    "\n",
    "if not RUNNING_LOCALLY:\n",
    "    os.chdir(\"/home/yash/\")\n",
    "    print(\"Current Directory ->\", os.getcwd())\n",
    "\n",
    "    WORKING_DIRECTORY = \"/home/yash/working_dir/\"\n",
    "\n",
    "    # Ensure that you are working in the right environment\n",
    "    !echo $CONDA_PREFIX\n",
    "\n",
    "LOG_FILE = WORKING_DIRECTORY + \"log_file.txt\"\n",
    "\n",
    "def write_to_log(statement, include_blank_line=False):\n",
    "    try:\n",
    "        with open(LOG_FILE, \"a\") as myfile:\n",
    "            if include_blank_line:\n",
    "                myfile.write(\"\\n\\n\" + statement)\n",
    "            else:\n",
    "                myfile.write(\"\\n\" + statement)\n",
    "    except:\n",
    "        # Running this locally may cause errors, and isn't required\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a7379d-5c58-4894-8c21-8950478d0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 19:26:32.982096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-05 19:26:32.982122: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/yash/Desktop/Courses/CS2470/Final_Project/proj_env/lib/python3.7/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/Desktop/Courses/CS2470/Final_Project/proj_env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/home/yash/Desktop/Courses/CS2470/Final_Project/proj_env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/home/yash/Desktop/Courses/CS2470/Final_Project/proj_env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/home/yash/Desktop/Courses/CS2470/Final_Project/proj_env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  if hasattr(pil_image, 'HAMMING'):\n",
      "/home/yash/Desktop/Courses/CS2470/Final_Project/proj_env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  if hasattr(pil_image, 'BOX'):\n",
      "/home/yash/Desktop/Courses/CS2470/Final_Project/proj_env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if hasattr(pil_image, 'LANCZOS'):\n",
      "2022-05-05 19:26:34.379039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-05 19:26:34.379079: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-05 19:26:34.379097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (yash-ThinkPad-L390): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.wrappers import RecordVideo\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f24a5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatObs(gym.Wrapper):\n",
    "    def __init__(self, env, k):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.k = k\n",
    "        self.frames = deque([], maxlen=k)\n",
    "        shp = env.observation_space.shape\n",
    "        self.observation_space = \\\n",
    "            spaces.Box(low=0, high=255, shape=((k,) + shp), dtype=env.observation_space.dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        ob = self.env.reset()\n",
    "        for _ in range(self.k):\n",
    "            self.frames.append(ob)\n",
    "        return self._get_ob()\n",
    "\n",
    "    def step(self, action):\n",
    "        ob, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(ob)\n",
    "        return self._get_ob(), reward, done, info\n",
    "\n",
    "    def _get_ob(self):\n",
    "        return np.array(self.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7cfe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bunch of wrappers to get us started, please use these\n",
    "class ObservationWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, GRAYSCALE=False, NORMALIZE=False):\n",
    "        self.GRAYSCALE = GRAYSCALE\n",
    "        self.NORMALIZE = NORMALIZE\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def observation(self, obs):\n",
    "        # Normalise observation by 255\n",
    "\n",
    "        \n",
    "        if self.NORMALIZE:\n",
    "            obs = obs / 255.0\n",
    "        # Convert to grayscale -> This isn't quite working right now, but we can update the function quite easily later\n",
    "        if self.GRAYSCALE:\n",
    "#             obs = obs\n",
    "            obs = tf.image.rgb_to_grayscale(obs)\n",
    "                    \n",
    "        image = obs[:,2:-9,8:,:]\n",
    "        image = tf.image.resize(image,[84,84])\n",
    "        image = tf.transpose(tf.reshape(image, image.shape[:-1]),perm = [1,2,0])\n",
    "        return image\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, reward):\n",
    "        # Clip reward between 0 to 1\n",
    "        return np.clip(reward, 0, 1)\n",
    "    \n",
    "class ActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def action(self, action):\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "929c1702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/Desktop/Courses/CS2470/Final_Project/proj_env/lib/python3.7/site-packages/gym/wrappers/record_video.py:42: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/yash/Desktop/Courses/CS2470/Final_Project/working_dir/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  f\"Overwriting existing videos at {self.video_folder} folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\"\n"
     ]
    }
   ],
   "source": [
    "# Using the wrappers for the environment\n",
    "model_name = \"random_model\"\n",
    "env = gym.make(\"ALE/Riverraid-v5\")\n",
    "env = ObservationWrapper(RewardWrapper(ActionWrapper(ConcatObs(env, 4))), GRAYSCALE=True, NORMALIZE=True)\n",
    "env = RecordVideo(env, video_folder=WORKING_DIRECTORY+\"videos/\", name_prefix=model_name+\"_\")\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff60ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = WORKING_DIRECTORY + \"model/cDQN_100\"\n",
    "# q_net = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1053a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done = False\n",
    "num_steps = 10**6\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    if info['lives'] < 4:\n",
    "        break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5edc442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'lives': 3, 'episode_frame_number': 1292, 'frame_number': 1292}, 0.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b3e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "interpreter": {
   "hash": "b8bd69ed4ffee0ae412486d98ceaaadb3fa2922e6e180ca66d279a33125fa193"
  },
  "kernelspec": {
   "display_name": "atari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
